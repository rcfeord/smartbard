{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiO0aQuyhmD6"
      },
      "source": [
        "# Testing GPT-2-simple"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNjtAIb4UBkw",
        "outputId": "8da2166a-5326-4e31-9706-7976d216abb8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gpt_2_simple"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIQIek6riO6l",
        "outputId": "50dded11-556e-4e86-da18-d0789b1082b3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpt-2-simple: filename=gpt_2_simple-0.8.1-py3-none-any.whl size=24576 sha256=34403f5d136741d9f0da4c87d7ffba456082621568b889d2794304032d6d2785\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/89/8a/f5de6944286d1ac2658b0caa7eae3c8cda50f770cdc957217f\n",
            "Successfully built gpt-2-simple\n",
            "Installing collected packages: toposort, gpt-2-simple\n",
            "Successfully installed gpt-2-simple-0.8.1 toposort-1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DYtjLGRdhmD8"
      },
      "outputs": [],
      "source": [
        "import gpt_2_simple as gpt2\n",
        "import os\n",
        "import requests\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KotC6ui9hmD-",
        "outputId": "22a0cdc9-03a1-420e-9bb2-9d98b5dbc7ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 124M model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 425Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:01, 571kit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 528Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [01:21, 6.15Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 378Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:01, 857kit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:01, 859kit/s]\n"
          ]
        }
      ],
      "source": [
        "# Download GPT-2 124M model\n",
        "model_name = \"124M\"\n",
        "if not os.path.isdir(os.path.join(\"models\", model_name)):\n",
        "    print(f\"Downloading {model_name} model...\")\n",
        "    gpt2.download_gpt2(model_name=model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mWfSBM60hmD_"
      },
      "outputs": [],
      "source": [
        "#file_name = \"shakespeare.txt\"\n",
        "#if not os.path.isfile(file_name):\n",
        "#    url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "#    data = requests.get(url)\n",
        "    \n",
        "#    with open(file_name, 'w') as f:\n",
        "#        f.write(data.text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#file_name = \"limericks.txt\"\n",
        "file_name = 'a_lines.txt'\n",
        "#file_name = 'b_lines.txt'"
      ],
      "metadata": {
        "id": "39rLva80-DJ-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = 'checkpoint'\n",
        "run_name = 'run1'\n",
        "\n",
        "#tf.reset_default_graph()\n",
        "tf.compat.v1.reset_default_graph()"
      ],
      "metadata": {
        "id": "UvJUd08RpBP_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6_3rJ4DhmEA",
        "outputId": "d0ab2706-3eed-4fdc-c4ea-948d2a4018e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint checkpoint/run1/model-100\n",
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 3423.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset has 11145 tokens\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======== SAMPLE 1 ========\n",
            " yes.\n",
            "My son's a chemist, heh.\n",
            "He plays sports, I think,\n",
            "But the way he plays sports,\n",
            "The way he walks, the the way he eats,\n",
            "It's the same everywhere.\n",
            "\n",
            "The only difference is, whenever he's down\n",
            "It's natural.\n",
            "I feel bad for my son.\n",
            "He was just a little ahead of his times.\n",
            "\n",
            "His testicles did grow;\n",
            "They're small, just 3/4\" across.\n",
            "They're full of hormones,\n",
            "So why not sprinkle some on your gran?\n",
            "\n",
            "They're just exercise for stormwater.\n",
            "\n",
            "I'm not a doctor right now,\n",
            "So I'm not very familiar\n",
            "With the disease that's wreaking havoc\n",
            "On a loved one.\n",
            "The disease's not cancer,\n",
            "It's just a hormonal imbalance.\n",
            "\n",
            "So the thought of it keeps me up nights.\n",
            "\n",
            "I just want to sleep in the warm alcove.\n",
            "That's it, you're free to go.\n",
            "You've got no compunction\n",
            "In seeking a reason why:\n",
            "For a reason, a reason has.\n",
            "It's not just a dream,\n",
            "It's a reality.\n",
            "I'm a member of A A R P.\n",
            "I enlisted on my jubilee.\n",
            "Hot damn, I'm retired\n",
            "And not yet expired,\n",
            "So I'm off to go surf Waikiki.*\n",
            "\n",
            "There once was a sheik named Abdul\n",
            "Who caused congresspersons to drool.\n",
            "He offered them bribes;\n",
            "They misread the vibes:\n",
            "ABSCAM was the FBI's tool.\n",
            "\n",
            "Akhenaten to his wife Nefertiti\n",
            "Wrote in hieroglyphs, not in graffiti:\n",
            "\"I'll locate your tomb\n",
            "In the abapical room\n",
            "And not at the apex, my sweetie.\"\n",
            "\n",
            "My abri is the place meant for me.\n",
            "It's a hole in a hill where I flee:\n",
            "Gives me shelter from storm,\n",
            "Keeps me cozy and warm —\n",
            "I can hide, settle back, sip Chablis.\n",
            "\n",
            "Do you suffer from PTSD?\n",
            "Abreact and you'll finally be free\n",
            "Of the stress and the strife\n",
            "That has messed up your life.\n",
            "Reliving the trauma's the key.\n",
            "\n",
            "Abaxile's a word that can mean\n",
            "Away from the axis, as seen\n",
            "In an apple whose core\n",
            "Is off center; what's more,\n",
            "That's true if it's red or it's green.\n",
            "\n",
            "The percent of the sun's radiation\n",
            "That gets stuck in a window's translation:\n",
            "Absorptance, it's called\n",
            "When the energy's stalled —\n",
            "It's sort of like glass constipation.\n",
            "\n",
            "The Department of Homeland Security,\n",
            "With all of their brains and maturity,\n",
            "Says, \"The threat is Code Red;\n",
            "Expect to be dead.\"\n",
            "An advis'rance not marked by obscurity.\n",
            "\n",
            "The adzukis are beans from Japan\n",
            "Colored burgundy red, rarely tan.\n",
            "Their sprouts have a taste like pecan.\n",
            "The taste is sweet, but not quite sweet.\n",
            "When you're walking along on the strand,\n",
            "The adlittoral's quite a thin band.\n",
            "It's the part that's just kissed\n",
            "By the spray and the mist;\n",
            "It's not really water; it's land.\n",
            "\n",
            "The dogfish of Erie looks funny;\n",
            "The Finger Lake's bowfin costs money.\n",
            "Deny if you wish,\n",
            "These are the same fish:\n",
            "Amia is fresh-water tunny.\n",
            "\n",
            "If lazy-eye darkens your view\n",
            "Or poisons corrupted that too,\n",
            "Or you go for some ethyl\n",
            "But get too much methyl —\n",
            "Amblyopia's what's ailing you.\n",
            "\n",
            "Not long after photos began,\n",
            "One \"type\" was a flash in the pan.\n",
            "Daguerre had a winner,\n",
            "And tin-types were thinner,\n",
            "So ambrotype's glass \"also-ran.\"\n",
            "\n",
            "Great Jupiter's loves are his moons;\n",
            "His girdle each orbit festoons.\n",
            "His surrogate mother\n",
            "Is tempted to smother:\t\t\n",
            "Amalthea, third of the lunes.\n",
            "\n",
            "A well-spoken young Indonesian\n",
            "Contracted a cortical lesion.\n",
            "\tHis sentences hence\n",
            "\tNo longer made sense:\n",
            "Acataphasia wrecks verbal cohesion.\n",
            "\n",
            "Grandpa Abraham: earliest Jew\n",
            "(Ditto Christians and Muslim folk too).\n",
            "God enjoined: \"Kill your son!\"\n",
            "'Twas about to be done!\n",
            "Then an angel said, \"No, that'll do.\"\n",
            "\n",
            "Accho is a town, if you please\n",
            "Though its name reminds one of a sneeze.\n",
            "\tIt might sound like a cold\n",
            "\tBut it's Biblical (old\n",
            "\n",
            "[101 | 19.63] loss=3.54 avg=3.54\n",
            "[102 | 21.97] loss=8.63 avg=6.10\n",
            "[103 | 24.29] loss=5.66 avg=5.95\n",
            "[104 | 26.60] loss=3.45 avg=5.31\n",
            "[105 | 28.90] loss=3.72 avg=4.99\n",
            "[106 | 31.21] loss=2.78 avg=4.61\n",
            "[107 | 33.49] loss=4.12 avg=4.54\n",
            "[108 | 35.74] loss=3.21 avg=4.37\n",
            "[109 | 37.99] loss=3.55 avg=4.27\n",
            "[110 | 40.24] loss=1.95 avg=4.03\n",
            "[111 | 42.49] loss=3.16 avg=3.95\n",
            "[112 | 44.75] loss=3.39 avg=3.90\n",
            "[113 | 46.98] loss=2.53 avg=3.79\n",
            "[114 | 49.22] loss=3.52 avg=3.77\n",
            "[115 | 51.45] loss=3.08 avg=3.72\n",
            "[116 | 53.69] loss=3.00 avg=3.67\n",
            "[117 | 55.93] loss=2.16 avg=3.57\n",
            "[118 | 58.16] loss=3.50 avg=3.57\n",
            "[119 | 60.39] loss=3.36 avg=3.56\n",
            "[120 | 62.62] loss=2.75 avg=3.51\n",
            "[121 | 64.85] loss=2.42 avg=3.45\n",
            "[122 | 67.09] loss=1.94 avg=3.38\n",
            "[123 | 69.32] loss=1.86 avg=3.30\n",
            "[124 | 71.56] loss=2.61 avg=3.27\n",
            "[125 | 73.80] loss=2.56 avg=3.24\n",
            "[126 | 76.04] loss=2.41 avg=3.20\n",
            "[127 | 78.29] loss=2.34 avg=3.17\n",
            "[128 | 80.55] loss=2.76 avg=3.15\n",
            "[129 | 82.81] loss=2.49 avg=3.12\n",
            "[130 | 85.07] loss=1.95 avg=3.08\n",
            "[131 | 87.33] loss=2.04 avg=3.04\n",
            "[132 | 89.59] loss=2.47 avg=3.02\n",
            "[133 | 91.86] loss=2.50 avg=3.00\n",
            "[134 | 94.12] loss=2.23 avg=2.98\n",
            "[135 | 96.40] loss=1.59 avg=2.93\n",
            "[136 | 98.68] loss=1.57 avg=2.88\n",
            "[137 | 100.96] loss=1.91 avg=2.85\n",
            "[138 | 103.21] loss=2.08 avg=2.83\n",
            "[139 | 105.49] loss=1.82 avg=2.80\n",
            "[140 | 107.77] loss=1.16 avg=2.75\n",
            "[141 | 110.04] loss=1.50 avg=2.71\n",
            "[142 | 112.31] loss=2.09 avg=2.69\n",
            "[143 | 114.59] loss=1.35 avg=2.65\n",
            "[144 | 116.84] loss=1.72 avg=2.63\n",
            "[145 | 119.11] loss=1.74 avg=2.60\n",
            "[146 | 121.37] loss=1.49 avg=2.57\n",
            "[147 | 123.62] loss=1.49 avg=2.54\n",
            "[148 | 125.88] loss=1.11 avg=2.51\n",
            "[149 | 128.14] loss=1.27 avg=2.48\n",
            "[150 | 130.39] loss=1.22 avg=2.44\n",
            "[151 | 132.64] loss=1.02 avg=2.41\n",
            "[152 | 134.89] loss=0.74 avg=2.37\n",
            "[153 | 137.15] loss=0.90 avg=2.33\n",
            "[154 | 139.40] loss=0.77 avg=2.29\n",
            "[155 | 141.66] loss=0.68 avg=2.26\n",
            "[156 | 143.91] loss=0.73 avg=2.22\n",
            "[157 | 146.17] loss=0.82 avg=2.19\n",
            "[158 | 148.42] loss=0.97 avg=2.16\n",
            "[159 | 150.68] loss=0.85 avg=2.13\n",
            "[160 | 152.94] loss=0.81 avg=2.10\n",
            "[161 | 155.19] loss=0.62 avg=2.07\n",
            "[162 | 157.45] loss=0.43 avg=2.04\n",
            "[163 | 159.71] loss=0.46 avg=2.00\n",
            "[164 | 161.97] loss=0.67 avg=1.97\n",
            "[165 | 164.23] loss=0.70 avg=1.95\n",
            "[166 | 166.49] loss=0.32 avg=1.91\n",
            "[167 | 168.74] loss=0.37 avg=1.88\n",
            "[168 | 171.00] loss=0.32 avg=1.85\n",
            "[169 | 173.25] loss=0.57 avg=1.82\n",
            "[170 | 175.51] loss=0.34 avg=1.80\n",
            "[171 | 177.77] loss=0.27 avg=1.77\n",
            "[172 | 180.03] loss=0.23 avg=1.74\n",
            "[173 | 182.29] loss=0.25 avg=1.71\n",
            "[174 | 184.54] loss=0.28 avg=1.68\n",
            "[175 | 186.80] loss=0.24 avg=1.65\n",
            "[176 | 189.05] loss=0.18 avg=1.63\n",
            "[177 | 191.31] loss=0.18 avg=1.60\n",
            "[178 | 193.56] loss=0.18 avg=1.57\n",
            "[179 | 195.82] loss=0.16 avg=1.55\n",
            "[180 | 198.09] loss=0.13 avg=1.52\n",
            "[181 | 200.35] loss=0.25 avg=1.50\n",
            "[182 | 202.60] loss=0.11 avg=1.47\n",
            "[183 | 204.85] loss=0.09 avg=1.45\n",
            "[184 | 207.11] loss=0.09 avg=1.43\n",
            "[185 | 209.38] loss=0.15 avg=1.40\n",
            "[186 | 211.64] loss=0.08 avg=1.38\n",
            "[187 | 213.89] loss=0.11 avg=1.36\n",
            "[188 | 216.15] loss=0.19 avg=1.34\n",
            "[189 | 218.41] loss=0.08 avg=1.32\n",
            "[190 | 220.66] loss=0.08 avg=1.30\n",
            "[191 | 222.92] loss=0.06 avg=1.28\n",
            "[192 | 225.20] loss=0.05 avg=1.26\n",
            "[193 | 227.45] loss=0.06 avg=1.24\n",
            "[194 | 229.71] loss=0.04 avg=1.22\n",
            "[195 | 231.97] loss=0.06 avg=1.20\n",
            "[196 | 234.23] loss=0.06 avg=1.18\n",
            "[197 | 236.48] loss=0.08 avg=1.16\n",
            "[198 | 238.74] loss=0.06 avg=1.14\n",
            "[199 | 241.00] loss=0.05 avg=1.13\n",
            "[200 | 243.26] loss=0.06 avg=1.11\n",
            "Saving checkpoint/run1/model-200\n"
          ]
        }
      ],
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.finetune(sess,\n",
        "              file_name,\n",
        "              model_name=model_name,\n",
        "              checkpoint_dir=checkpoint_dir,\n",
        "              run_name=run_name,\n",
        "#              overwrite=True,\n",
        "              steps=100)   # steps is max number of training steps"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.generate(sess)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uq2G9vB7jH66",
        "outputId": "e3ad02ca-2389-4548-a141-c85fe74cb179"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is methylation?\n",
            "\n",
            "The building's not very nice.\n",
            "\n",
            "It's a very big house.\n",
            "\n",
            "And it should be free of crawl space.\n",
            "\n",
            "An immense amount of waste is dumped every day.\n",
            "\n",
            "Alcaeus, the Roman city that is now my new capital.\n",
            "\n",
            "This latest of those \"dumb trees\" strikes me as quite unsurprising.\n",
            "\n",
            "But the city has changed hands many times in the course of a week.\n",
            "\n",
            "It seems, I fear, that the harebrained strand goes under.\n",
            "\n",
            "The beast that bites — the slavering predator.\n",
            "\n",
            "The young of Atlas well on their own prey,\n",
            "\n",
            "But in a slumber in a freezing storage shed.\n",
            "\n",
            "They're savage animals, but I've never seen one with huge jaws.\n",
            "\n",
            "\"Oh yes, petulance is a virtue.\n",
            "\n",
            "But students struggle to an upright stand\n",
            "\n",
            "While their essays are taken in.\n",
            "\n",
            "In a calculated move, they've flipped through their volumes.\n",
            "\n",
            "The Lamaze Copter is no slouch.\n",
            "\n",
            "It thaws the beast in the claws!\n",
            "\n",
            "My Lamaze Bentley is no slouch!\n",
            "\n",
            "It thaws the beast in the thigh?  No way!\n",
            "\n",
            "That's excusable, madam.\n",
            "\n",
            "But also you and me.  No way!\n",
            "\n",
            "Abuse is abuse, please don't do it.\n",
            "\n",
            " Madam, you really are so bold.\n",
            "\n",
            "This limerick needs no explanation\n",
            "\n",
            "And its rhymes have a stable foundation,\n",
            "\n",
            "I'm afraid.\n",
            "\n",
            "It is vital for our times to have an endearment standard\n",
            "\n",
            "That isnthoider myDAW\n",
            "\n",
            "And not my airbrush.\n",
            "\n",
            "Thoicalists are rare,\n",
            "\n",
            "Being aictionians bold\n",
            "\n",
            "And authors with aplomb.\n",
            "\n",
            "Phlegmologists guess\n",
            "\n",
            "That it's not in writing, guys.\n",
            "\n",
            "It is, alas, an afterthought.\n",
            "\n",
            "Now here is a reason:\n",
            "\n",
            "To explain why the dawn of day\n",
            "\n",
            "In the west came with the fall of Rome.\n",
            "\n",
            "The healing arts areducans\n",
            "\n",
            "That save face-off, which is to say, sit still\n",
            "\n",
            "While your tampon is on the go.\n",
            "\n",
            "The women who suffer form a taboo.\n",
            "\n",
            "Acrostic sleep help might do you good.\n",
            "\n",
            "The ache in your belly that doctors warn\n",
            "\n",
            "Can lead, I'm afraid, to a state of abasement.\n",
            "\n",
            "Sleep apnea is I a-hole silence.\n",
            "\n",
            "It is a disease, suppose you please,\n",
            "\n",
            "That causes you to stay in the dark.\n",
            "\n",
            "Aasuropodidae on your veranda?\n",
            "\n",
            "Look at that! Holy cow! Giant panda!\n",
            "\n",
            "When he sent you those twelve memoranda.\n",
            "\n",
            "To memoranda. The thing that's on your mind?\n",
            "\n",
            "To find them all on your desk.\n",
            "\n",
            "These twelve words team Bears Loves,\n",
            "\n",
            "All twelve of you: \"back to square one.\"\n",
            "\n",
            "A long time back to the days of \"Twentynine for lawn mower.\"\n",
            "\n",
            "Now these are the words we tell friends and family:\n",
            "\n",
            "\"All twelve in the afternoon.\"\n",
            "\n",
            "And these are our words of encouragement:\n",
            "\n",
            "\n",
            "To hate-enjoy life too!\n",
            "\n",
            "Although the weather can be nasty,\n",
            "\n",
            "Not a whit scorchingly so.\n",
            "\n",
            "An alien's not from your place.\n",
            "\n",
            "This can lead, I'm afraid,\n",
            "\n",
            "To the North Pole, where we're chill-stricken.\n",
            "\n",
            "And you'd better be careful what you wish for your possessions.\n",
            "\n",
            "This can lead, I'm afraid, to a Mexican's.\n",
            "\n",
            "It's called apologia homily.\n",
            "\n",
            "Self-denial is a defense,\n",
            "\n",
            "But the world will never know.\n",
            "\n",
            "The contrabalinist belief that's in every pack.\n",
            "\n",
            "Theanias, the stand-ins for a beer\n",
            "\n",
            "(It's the Latin acronym for Cashout Day),\n",
            "\n",
            "Offered by their insurance,\n",
            "\n",
            "They hoped they'd win the next Nobel.\n",
            "\n",
            "The Anabaptists are a confusing beast.\n",
            "\n",
            "Their systems are quite familiar,\n",
            "\n",
            "From the Old Testament, when the blind was more accessible.\n",
            "\n",
            "One might suppose, then,\n",
            "\n",
            "That adherence to a set of belief systems\n",
            "\n",
            "Is a form of homily, reciting praise in praise.\n",
            "\n",
            "The Aeneas, Greek for \"point,\"\n",
            "\n",
            "And they were surely wrong.\n",
            "\n",
            "The fallacy of belief, then,\n",
            "\n",
            "As Peter had said,\n",
            "\n",
            "Is that you really sure you're Christ?\n",
            "\n",
            "The one who's lying to himself,\n",
            "\n",
            "The other to the truth.\n",
            "\n",
            "The dearly departed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.generate(sess, length=50, temperature=0.8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-gknmHrCLoD",
        "outputId": "0b33442a-c1c9-4dda-8f97-d726e40250d9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is my iced-in-the-air. It's great when the play is already done\n",
            "\n",
            "But I've got a hard time keeping things simple\n",
            "\n",
            "With a id and a whistle\n",
            "\n",
            "And I forget where I'm pointing\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit ('smartbard')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "24f0a4b62e4010e93576611bcdc48e6f6a12ca25bf673138b4d5728aafed3228"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}